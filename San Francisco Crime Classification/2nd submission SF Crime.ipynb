{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read crime data\n",
    "try:\n",
    "    crime_data = pd.read_csv(\"train.csv\", parse_dates=['Dates'])\n",
    "    print \"Data read successfully!\"\n",
    "except:\n",
    "    print \"Dataset could not be loaded. Is the dataset missing?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crime_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean up some bad values, there are some locations in the dataset that are not in San Francisco\n",
    "crime_data = crime_data[crime_data['Y'] < 38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crimeCatagories = crime_data[\"Category\"].unique()\n",
    "crimeCatagories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_ = [\n",
    "    'Dates', #timestamp of the crime incident\n",
    "    #'Category', #category of the crime incident (only in train.csv). This is the target variable you are going to predict.\n",
    "    'Descript', #detailed description of the crime incident (only in train.csv)\n",
    "    #'DayOfWeek', #the day of the week\n",
    "    #'PdDistrict', #name of the Police Department District\n",
    "    'Resolution', #how the crime incident was resolved (only in train.csv)\n",
    "    'Address', #the approximate street address of the crime incident \n",
    "    #'X', #Longitude\n",
    "    #'Y' #Latitude\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "addresses=sorted(crime_data[\"Address\"].unique())\n",
    "categories=sorted(crime_data[\"Category\"].unique())\n",
    "C_counts=crime_data.groupby([\"Category\"]).size()\n",
    "A_C_counts=crime_data.groupby([\"Address\",\"Category\"]).size()\n",
    "A_counts=crime_data.groupby([\"Address\"]).size()\n",
    "logodds={}\n",
    "logoddsPA={}\n",
    "MIN_CAT_COUNTS=2\n",
    "default_logodds=np.log(C_counts/len(crime_data))-np.log(1.0-C_counts/float(len(crime_data)))\n",
    "for addr in addresses:\n",
    "    PA=A_counts[addr]/float(len(crime_data))\n",
    "    logoddsPA[addr]=np.log(PA)-np.log(1.-PA)\n",
    "    logodds[addr]=deepcopy(default_logodds)\n",
    "    for cat in A_C_counts[addr].keys():\n",
    "        if (A_C_counts[addr][cat]>MIN_CAT_COUNTS) and A_C_counts[addr][cat]<A_counts[addr]:\n",
    "            PA=A_C_counts[addr][cat]/float(A_counts[addr])\n",
    "            logodds[addr][categories.index(cat)]=np.log(PA)-np.log(1.0-PA)\n",
    "    logodds[addr]=pd.Series(logodds[addr])\n",
    "    logodds[addr].index=range(len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_season(x):\n",
    "    summer=0\n",
    "    fall=0\n",
    "    winter=0\n",
    "    spring=0\n",
    "    if (x in [5, 6, 7]):\n",
    "        summer=1\n",
    "    if (x in [8, 9, 10]):\n",
    "        fall=1\n",
    "    if (x in [11, 0, 1]):\n",
    "        winter=1\n",
    "    if (x in [2, 3, 4]):\n",
    "        spring=1\n",
    "    return summer, fall, winter, spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PreProcess(data,test_data = False):\n",
    "\n",
    "\n",
    "    #Convert Dates Column to Year, Month, Day, Hour individual columns\n",
    "    data['Year'] = data['Dates'].map(lambda x: x.year)\n",
    "    data['Month'] = data['Dates'].map(lambda x: x.month)\n",
    "    data['Day'] = data['Dates'].map(lambda x: x.day) \n",
    "    data['Hour'] = data['Dates'].map(lambda x: x.hour) \n",
    "    \n",
    "    data[\"Awake\"]=data[\"Hour\"].apply(lambda x: 1 if (x==0 or (x>=8 and x<=23)) else 0)\n",
    "    data[\"Summer\"], data[\"Fall\"], data[\"Winter\"], data[\"Spring\"]=zip(*data[\"Month\"].apply(get_season))\n",
    "    \n",
    "    # Creating address features\n",
    "    address_features=data[\"Address\"].apply(lambda x: logodds[x])\n",
    "    address_features.columns=[\"logodds\"+str(x) for x in range(len(address_features.columns))]\n",
    "    \n",
    "    data = pd.concat([data, address_features], axis=1)\n",
    "    \n",
    "    data[\"IsInterection\"]=data[\"Address\"].apply(lambda x: 1 if \"/\" in x else 0)\n",
    "    data[\"logoddsPA\"]=data[\"Address\"].apply(lambda x: logoddsPA[x])\n",
    "    \n",
    "    #Drop unneccessary columns\n",
    "    if not test_data:\n",
    "        data = data.drop(columns_, 1)\n",
    "    else:\n",
    "        data = data.drop(['Id','Dates','Address'], 1)\n",
    "            \n",
    "    \n",
    "    # Preprocess feature columns\n",
    "    outX = pd.DataFrame(index=data.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in data.iteritems():\n",
    "        # If non-numeric, convert to one or more dummy variables\n",
    "        if (col_data.dtype == object):\n",
    "            col_data = pd.get_dummies(col_data)  # e.g. 'PdDistrict\n",
    "\n",
    "        outX = outX.join(col_data)  # collect column(s) in output dataframe\n",
    "        \n",
    "    #from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    #stdsclr = StandardScaler()\n",
    "    #outX[['Year','Month','Day', 'Hour','X','Y']] = stdsclr.fit_transform(outX[['Year','Month','Day', 'Hour','X','Y']])    \n",
    "\n",
    "    return outX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_crime_data = PreProcess(crime_data)\n",
    "processed_crime_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_cols = crimeCatagories\n",
    "feature_cols = processed_crime_data.columns.difference(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdsclr = StandardScaler()\n",
    "processed_crime_data[feature_cols]= stdsclr.fit_transform(processed_crime_data[feature_cols])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all = processed_crime_data[feature_cols]\n",
    "X_all = X_all.sort_index(axis=1) #Sort Columns\n",
    "y_all = processed_crime_data[target_cols]\n",
    "y_all = y_all.sort_index(axis=1) #Sort Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all,test_size=0.3)\n",
    "print \"Done split!\"\n",
    "\n",
    "print \"Number of Training set: {}\".format(len(X_train)) \n",
    "print \"Number of Testing set: {}\".format(len(X_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "import datetime\n",
    "a = datetime.datetime.now()\n",
    "clf = OneVsRestClassifier(GradientBoostingClassifier(n_estimators=50, learning_rate=1.0,max_depth=4, random_state=0))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "b = datetime.datetime.now()\n",
    "print b - a\n",
    "print \"Done fitting!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read Crime Test Data\n",
    "crime_test_data = pd.read_csv(\"test.csv\", parse_dates=['Dates'])\n",
    "print \"Data read successfully!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_addresses=sorted(crime_test_data[\"Address\"].unique())\n",
    "new_A_counts=crime_test_data.groupby(\"Address\").size()\n",
    "only_new=set(new_addresses+addresses)-set(addresses)\n",
    "only_old=set(new_addresses+addresses)-set(new_addresses)\n",
    "in_both=set(new_addresses).intersection(addresses)\n",
    "for addr in only_new:\n",
    "    PA=new_A_counts[addr]/float(len(crime_test_data)+len(crime_data))\n",
    "    logoddsPA[addr]=np.log(PA)-np.log(1.-PA)\n",
    "    logodds[addr]=deepcopy(default_logodds)\n",
    "    logodds[addr].index=range(len(categories))\n",
    "for addr in in_both:\n",
    "    PA=(A_counts[addr]+new_A_counts[addr])/float(len(crime_test_data)+len(crime_data))\n",
    "    logoddsPA[addr]=np.log(PA)-np.log(1.-PA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processed_crime_test_data = PreProcess(crime_test_data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processed_crime_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = processed_crime_test_data.columns.tolist()\n",
    "processed_crime_test_data[feature_cols]= stdsclr.fit_transform(processed_crime_test_data[feature_cols]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processed_crime_test_data = processed_crime_test_data.sort_index(axis=1) #Sort Columns\n",
    "processed_crime_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_class_test = clf.predict_proba(processed_crime_test_data)\n",
    "print \"Prediction done!\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print y_pred_class_test[6][100:125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to CSV\n",
    "submission = pd.DataFrame(y_pred_class_test, columns=target_cols)\n",
    "submission = submission.sort_index(axis=1)\n",
    "#add Id column to the as the first column with datafarame index as its values.\n",
    "submission.insert(0, 'Id',  processed_crime_test_data.index, allow_duplicates=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.to_csv('C:\\Python\\Submission.csv', index=False, header=True)\n",
    "print \"Done with Dataframe Conversion to a Csv File!\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
