{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project : Kobe Bryant Shot Selection\n",
    "### Which shots did Kobe sink? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification vs Regression\n",
    "\n",
    "which type of supervised machine learning problem is this, classification or regression? Why?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "This is a classification problem. Classification is simply the process of taking some kind of input and mapping it to some discrete label. In this problem, our goal is to predict whether or not a Kobe's shots find the bottom of the net (binary classification: yes, or no).\n",
    "\n",
    "Regression is more about continuous value function. So, something like giving a bunch of points and finding some real value for the new given point. \n",
    "\n",
    "The difference between classification and regression is the difference between mapping from some input to some small number of discrete values. And regression is mapping from some input space to some real number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring the Data\n",
    "\n",
    "Let's go ahead and read in the student dataset first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read successfully!\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "print \"Data read successfully!\"\n",
    "# Note: The column 'shot_made_flag' is the target/label, all other are feature columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, can you find out the following facts about the dataset?\n",
    "- Total number of shots\n",
    "- Number of made shots\n",
    "- Number missed shots\n",
    "- Rate of the class (%)\n",
    "- Number of features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ nan   0.   1.]\n",
      "Total number of shots: 30697\n",
      "Number of shots which Kobe made: 11465\n",
      "Number of shots which Kobe missed: 14232\n",
      "Rate of successful shots: 37.35%\n",
      "Number of features: 24\n"
     ]
    }
   ],
   "source": [
    "n_shots = data.shape[0] #Total number of shots\n",
    "n_features = data.shape[1] - 1  # The column \"shot_made_flag\", is the target label \n",
    "\n",
    "print data[\"shot_made_flag\"].unique()\n",
    "\n",
    "n_made = data[\"shot_made_flag\"].value_counts()[1]\n",
    "n_missed = data[\"shot_made_flag\"].value_counts()[0]\n",
    "\n",
    "rate = float( n_made ) / n_shots  * 100\n",
    "\n",
    "print \"Total number of shots: {}\".format(n_shots)\n",
    "print \"Number of shots which Kobe made: {}\".format(n_made)\n",
    "print \"Number of shots which Kobe missed: {}\".format(n_missed)\n",
    "print \"Rate of successful shots: {:.2f}%\".format(rate)\n",
    "\n",
    "print \"Number of features: {}\".format(n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing the Data\n",
    "In this section, we will prepare the data for modeling, training and testing.\n",
    "\n",
    "### Identify feature and target columns\n",
    "It is often the case that the data you obtain contains non-numeric features. This can be a problem, as most machine learning algorithms expect numeric data to perform computations with.\n",
    "\n",
    "Let's first separate our data into feature and target columns, and see if any features are non-numeric.<br/>\n",
    "**Note**: For this dataset, the column (`'shot_made_flag'`) is the target or label we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop useless columns\n",
    "def drop_columns(data, column_names):\n",
    "    new_data = data.drop(column_names, 1)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocess feature columns\n",
    "def preprocess_features(X):\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If non-numeric, convert to one or more dummy variables\n",
    "        if (col_data.dtype == object and col != 'season'):\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)  # e.g. 'action_type' => 'action_type_Jump Shot', \n",
    "                                                             #'action_type_Driving Dunk Shot'\n",
    "\n",
    "        outX = outX.join(col_data)  # collect column(s) in output dataframe\n",
    "\n",
    "    return outX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PreProcessData():\n",
    "    \n",
    "    Seasons = data[\"season\"].unique()\n",
    "\n",
    "    columns_ = [#'action_type',\n",
    "                'combined_shot_type',\n",
    "                'game_event_id',\n",
    "                'game_id',\n",
    "                'lat',\n",
    "                'loc_x',\n",
    "                'loc_y',\n",
    "                'lon',\n",
    "                'minutes_remaining',\n",
    "                'period',\n",
    "                'playoffs',\n",
    "                'season',\n",
    "                'seconds_remaining',\n",
    "                'shot_distance',\n",
    "                #'shot_made_flag' (this is what you are predicting),\n",
    "                'shot_type',\n",
    "                'shot_zone_area',\n",
    "                'shot_zone_basic',\n",
    "                'shot_zone_range',\n",
    "                'team_id',\n",
    "                'team_name',\n",
    "                'game_date',\n",
    "                'matchup',\n",
    "                'opponent',\n",
    "                #'shot_id'\n",
    "               ]\n",
    "\n",
    "    data['Away'] =  data.apply(home_away, axis = 1)\n",
    "    data_dropped = drop_columns(data,columns_)\n",
    "    data_dropped_processed = preprocess_features(data_dropped)\n",
    "\n",
    "    missing_data = data_dropped_processed.loc[data_dropped_processed['shot_made_flag'].isnull() == True]\n",
    "\n",
    "    good_data = data_dropped_processed.loc[data_dropped_processed['shot_made_flag'].isnull() == False]\n",
    "\n",
    "    target_col = 'shot_made_flag'  # This column is the target/label\n",
    "    feature_cols = [col for col in data_dropped_processed.columns if (col != 'shot_made_flag' and col != 'shot_id')]\n",
    "\n",
    "    X_all = good_data[feature_cols]\n",
    "    y_all = good_data[target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully shuffled and split the data!\n"
     ]
    }
   ],
   "source": [
    "# Put any import statements you need for this code block here\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "def shuffle_split_data(X, y):\n",
    "    \"\"\" Shuffles and splits data into 70% training and 30% testing subsets,\n",
    "        then returns the training and testing subsets. \"\"\"\n",
    "    \n",
    "    # Shuffle and split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # Return the training and testing data subsets\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "# Test shuffle_split_data\n",
    "try:\n",
    "    X_train, y_train, X_test, y_test = shuffle_split_data(X_all, y_all)\n",
    "    print \"Successfully shuffled and split the data!\"\n",
    "except:\n",
    "    print \"Something went wrong with shuffling and splitting the data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully performed a metric calculation!\n"
     ]
    }
   ],
   "source": [
    "# Put any import statements you need for this code block here\n",
    "from sklearn import metrics\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the total error between true and predicted values\n",
    "        based on a performance metric chosen by the student. \"\"\"\n",
    "    \n",
    "    return metrics.mean_squared_error(y_true, y_predict) #evaluate performance \n",
    "\n",
    "# Test performance_metric\n",
    "try:\n",
    "    total_error = performance_metric(y_train, y_train)\n",
    "    print \"Successfully performed a metric calculation!\"\n",
    "except:\n",
    "    print \"Something went wrong with performing a metric calculation.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fit a model!\n"
     ]
    }
   ],
   "source": [
    "# Put any import statements you need for this code block\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "def fit_model(X, y):\n",
    "    \"\"\" Tunes a decision tree regressor model using GridSearchCV on the input data X \n",
    "        and target labels y and returns this optimal model. \"\"\"\n",
    "\n",
    "    # Create a decision tree regressor object\n",
    "    regressor = DecisionTreeRegressor()\n",
    "\n",
    "    # Set up the parameters we wish to tune\n",
    "    parameters = {'max_depth':(1,2,3,4,5,6,7,8,9,10)}\n",
    "\n",
    "    # Make an appropriate scoring function\n",
    "    # functions ending with _error or _loss return a value to minimize, the lower the better\n",
    "    scoring_function = metrics.make_scorer(metrics.mean_squared_error, greater_is_better=False)\n",
    "\n",
    "    # Make the GridSearchCV object\n",
    "    reg = GridSearchCV(regressor, param_grid = parameters, scoring = scoring_function)\n",
    "\n",
    "    # Fit the learner to the data to obtain the optimal model with tuned parameters\n",
    "    reg.fit(X, y)\n",
    "\n",
    "    # Return the optimal model\n",
    "    return reg\n",
    "\n",
    "\n",
    "# Test fit_model on entire dataset\n",
    "try:\n",
    "    reg = fit_model(X_all, y_all)\n",
    "    print \"Successfully fit a model!\"\n",
    "except:\n",
    "    print \"Something went wrong with fitting a model.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def home_away(row):\n",
    "    if (row['matchup'].find('@')>0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction of admission\n",
    "missing_data_featurs = missing_data[feature_cols] \n",
    "shot_prediction = reg.predict(missing_data_featurs)\n",
    "\n",
    "# convert to CSV\n",
    "submission = pd.DataFrame({'shot_id': missing_data['shot_id'],\n",
    "                           'shot_made_flag': shot_prediction })\n",
    "\n",
    "submission[['shot_id', 'shot_made_flag']].to_csv('submission.csv', index=False)\n",
    "\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess feature columns\n",
    "\n",
    "As you can see, there are several non-numeric columns that need to be converted!These can be reasonably converted into `1`/`0` (binary) values.\n",
    "\n",
    "Other columns, like ` action_type` and `shot_zone_area `, have more than two values, and are known as _categorical variables_. The recommended way to handle such a column is to create as many columns as possible values (e.g. `action_type_Jump Shot`, `action_type_Driving Dunk`, etc.), and assign a `1` to one of them and `0` to all others.\n",
    "\n",
    "These generated columns are sometimes called _dummy variables_, and we will use the [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) function to perform this transformation.\n",
    "\n",
    "Here are columns that we want to transform:<br/>\n",
    "action_type,combined_shot_type,season,shot_type,shot_zone_area,shot_zone_basic,shot_zone_range,opponent\n",
    "\n",
    "We also want to eliminate columns that will provide no value to our final pridiction.\n",
    "game_event_id,game_id,team_id,team_name,game_date,shot_id\n",
    "\n",
    "There are 2 columns that need special attention:<br/>\n",
    "matchup : This column will be used to construct 2 additional columns as \"Home\" and \"Away\" which indicates wheather Kobe played at home or away."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Split data into training and test sets\n",
    "\n",
    "So far, we have converted all _categorical_ features into numeric values. In this next step, we split the data (both features and corresponding labels) into training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluating Models\n",
    "Choose 3 supervised learning models that are available in scikit-learn, and appropriate for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
